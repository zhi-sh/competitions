{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import lightgbm as lgb \n",
    "import xgboost as xgb \n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 设置显示全部列\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 29,
   "outputs": []
  },
  {
   "source": [
    "### 数据预操作"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_mem_usage 函数通过调整数据类型，帮助我们减少数据在内存中占用的空间\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum()  / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum()  / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory usage of dataframe is 366.21 MB\n",
      "2021-01-16 11:11:20,384 INFO: data shape: (1000000, 48)\n",
      "Memory usage after optimization is: 97.27 MB\n",
      "Decreased by 73.4%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  loanAmnt  term  interestRate  installment  employmentLength  \\\n",
       "0   0   35008.0     5     19.515625     918.0000               2.0   \n",
       "1   1   18000.0     5     18.484375     462.0000               5.0   \n",
       "2   2   12000.0     5     16.984375     298.2500               8.0   \n",
       "3   3   11000.0     3      7.261719     341.0000              10.0   \n",
       "4   4    3000.0     3     12.992188     101.0625               NaN   \n",
       "\n",
       "   homeOwnership  annualIncome  verificationStatus  isDefault  ...  n13  n14  \\\n",
       "0              2      110000.0                   2        1.0  ...  0.0  2.0   \n",
       "1              0       46000.0                   2        0.0  ...  0.0  2.0   \n",
       "2              0       74000.0                   2        0.0  ...  0.0  4.0   \n",
       "3              1      118000.0                   1        0.0  ...  0.0  1.0   \n",
       "4              1       29000.0                   2        0.0  ...  0.0  4.0   \n",
       "\n",
       "   issueDateDT  employmentTitle_cnts  employmentTitle_rank  postCode_cnts  \\\n",
       "0         2587                  1121                  1121           2075   \n",
       "1         1888                   125                   125           3789   \n",
       "2         3044                     1                     1           1754   \n",
       "3         2983                     2                     2            551   \n",
       "4         3196                 51149                 51149           1722   \n",
       "\n",
       "   postCode_rank  title_cnts  title_rank  sample  \n",
       "0           2075        7006        7006   train  \n",
       "1           3789          28          28   train  \n",
       "2           1754      393334      393334   train  \n",
       "3            551      148211      148211   train  \n",
       "4           1722        4731        4731   train  \n",
       "\n",
       "[5 rows x 48 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loanAmnt</th>\n      <th>term</th>\n      <th>interestRate</th>\n      <th>installment</th>\n      <th>employmentLength</th>\n      <th>homeOwnership</th>\n      <th>annualIncome</th>\n      <th>verificationStatus</th>\n      <th>isDefault</th>\n      <th>...</th>\n      <th>n13</th>\n      <th>n14</th>\n      <th>issueDateDT</th>\n      <th>employmentTitle_cnts</th>\n      <th>employmentTitle_rank</th>\n      <th>postCode_cnts</th>\n      <th>postCode_rank</th>\n      <th>title_cnts</th>\n      <th>title_rank</th>\n      <th>sample</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>35008.0</td>\n      <td>5</td>\n      <td>19.515625</td>\n      <td>918.0000</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>110000.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2587</td>\n      <td>1121</td>\n      <td>1121</td>\n      <td>2075</td>\n      <td>2075</td>\n      <td>7006</td>\n      <td>7006</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>18000.0</td>\n      <td>5</td>\n      <td>18.484375</td>\n      <td>462.0000</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>46000.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1888</td>\n      <td>125</td>\n      <td>125</td>\n      <td>3789</td>\n      <td>3789</td>\n      <td>28</td>\n      <td>28</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>12000.0</td>\n      <td>5</td>\n      <td>16.984375</td>\n      <td>298.2500</td>\n      <td>8.0</td>\n      <td>0</td>\n      <td>74000.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>3044</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1754</td>\n      <td>1754</td>\n      <td>393334</td>\n      <td>393334</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>11000.0</td>\n      <td>3</td>\n      <td>7.261719</td>\n      <td>341.0000</td>\n      <td>10.0</td>\n      <td>1</td>\n      <td>118000.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2983</td>\n      <td>2</td>\n      <td>2</td>\n      <td>551</td>\n      <td>551</td>\n      <td>148211</td>\n      <td>148211</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>3000.0</td>\n      <td>3</td>\n      <td>12.992188</td>\n      <td>101.0625</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>29000.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>3196</td>\n      <td>51149</td>\n      <td>51149</td>\n      <td>1722</td>\n      <td>1722</td>\n      <td>4731</td>\n      <td>4731</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data = pd.read_csv('data/data_for_model.csv')\n",
    "data = reduce_mem_usage(data)  # 节约n\n",
    "logging.info(f\"data shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((800000, 45), (200000, 45), (800000,))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#训练数据/测试数据\n",
    "\n",
    "features_to_drop = ['id','isDefault', 'sample']\n",
    "\n",
    "X_train = data.loc[data['sample'] == 'train', :].drop(features_to_drop, axis=1)\n",
    "X_test = data.loc[data['sample'] == 'test', :].drop(features_to_drop, axis=1)\n",
    "y_train = data.loc[data['sample'] == 'train', 'isDefault']\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "source": [
    "### 模型融合"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(X_train, y_train, X_test, y_test=None):\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    train_matrix = lgb.Dataset(X_train_split, label=y_train_split)\n",
    "    valid_matrix = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.01,\n",
    "        'min_child_weight': 0.32,\n",
    "        'num_leaves': 14,\n",
    "        'max_depth': 4,\n",
    "        'feature_fraction': 0.81,\n",
    "        'bagging_fraction': 0.61,\n",
    "        'bagging_freq': 9,\n",
    "        'min_data_in_leaf': 13,\n",
    "        'min_split_gain': 0.27,\n",
    "        'reg_alpha': 9.58,\n",
    "        'reg_lambda': 4.62,\n",
    "        'seed': 2020,\n",
    "        'n_jobs':-1,\n",
    "        'silent': True,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=500, early_stopping_rounds=200)\n",
    "    # 计算在验证集上的得分\n",
    "    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, val_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('调参后lightgbm单模型在验证集上的AUC：{}'.format(roc_auc))\n",
    "\n",
    "    # 对测试集进行预测\n",
    "    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    return test_pred\n",
    "\n",
    "def xgb_model(X_train, y_train, X_test, y_test=None):\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    train_matrix = xgb.DMatrix(X_train_split, label=y_train_split)\n",
    "    valid_matrix = xgb.DMatrix(X_val, label=y_val)\n",
    "    test_matrix = xgb.DMatrix(X_test)\n",
    "\n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'gamma': 1,\n",
    "        'min_child_weight': 1.5,\n",
    "        'max_depth': 5,\n",
    "        'lambda': 10,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'colsample_bylevel': 0.7,\n",
    "        'eta': 0.04,\n",
    "        'tree_method': 'exact',\n",
    "        'seed': 2020,\n",
    "        'n_jobs': -1,\n",
    "        \"silent\": True,\n",
    "    }\n",
    "\n",
    "    watchlist = [(train_matrix, 'train'), (valid_matrix, 'eval')]\n",
    "    model = xgb.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "    val_pred = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, val_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('调参后xgboost单模型在验证集上的AUC：{}'.format(roc_auc))\n",
    "\n",
    "    # 对测试集进行预测\n",
    "    test_pred = model.predict(test_matrix, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    return test_pred\n",
    "\n",
    "def cat_model(X_train, y_train, X_test, y_test=None):\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        task_type='CPU',\n",
    "        learning_rate=0.1,\n",
    "        iterations=500,\n",
    "        random_seed=2020,\n",
    "        od_type='Iter',\n",
    "        depth=7\n",
    "    )\n",
    "    model.fit(X_train_split, y_train_split, eval_set=(X_val, y_val), verbose=500, cat_features=col)\n",
    "    val_pred = model.predict(X_val)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, val_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('调参后catboost单模型在验证集上的AUC：{}'.format(roc_auc))\n",
    "\n",
    "    # 对测试集进行预测\n",
    "    test_pred = model.predict(X_test, prediction_type='Probability')[:, -1]\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Classifier\n",
    "\n",
    "model_dataset = Dataset(X_train=X_train, y_train=y_train, X_test=X_test)\n",
    "model_xgb = Classifier(dataset=model_dataset, estimator=xgb_model, name='xgb', use_cache=False)\n",
    "model_lgb = Classifier(dataset=model_dataset, estimator=lgb_model, name='lgb', use_cache=False)\n",
    "model_cat = Classifier(dataset=model_dataset, estimator=cat_model, name='cat', use_cache=False)"
   ]
  },
  {
   "source": [
    "#### 使用Stacking方法进行模型融合"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<heamy.pipeline.ModelsPipeline at 0x7fd636e2e0a0>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "from heamy.pipeline import ModelsPipeline\n",
    "\n",
    "pipeline = ModelsPipeline(model_cat, model_xgb, model_lgb)\n",
    "pipeline"
   ]
  },
  {
   "source": [
    "%%time \n",
    "\n",
    "# 构建第一层新特征， 其中K默认为5， 表示5折交叉验证， full_test=True, 对全部训练集进行训练得到基学习器，然后对测试集进行预测\n",
    "stack_ds = pipeline.stack(k=5, seed=2020, full_test=True)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-01-16 15:06:49,228 INFO: Calculating xgb's fold #1\n",
      "[15:06:50] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.69992\teval-auc:0.69903\n",
      "[200]\ttrain-auc:0.73367\teval-auc:0.72818\n",
      "[400]\ttrain-auc:0.74162\teval-auc:0.73212\n",
      "[600]\ttrain-auc:0.74716\teval-auc:0.73379\n",
      "[800]\ttrain-auc:0.75177\teval-auc:0.73481\n",
      "[1000]\ttrain-auc:0.75591\teval-auc:0.73522\n",
      "[1200]\ttrain-auc:0.75970\teval-auc:0.73558\n",
      "[1400]\ttrain-auc:0.76335\teval-auc:0.73580\n",
      "[1600]\ttrain-auc:0.76683\teval-auc:0.73584\n",
      "[1755]\ttrain-auc:0.76938\teval-auc:0.73576\n",
      "调参后xgboost单模型在验证集上的AUC：0.7358874704122116\n",
      "2021-01-16 15:20:49,873 INFO: Calculating xgb's fold #2\n",
      "[15:20:50] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.70119\teval-auc:0.70126\n",
      "[200]\ttrain-auc:0.73459\teval-auc:0.72799\n",
      "[400]\ttrain-auc:0.74266\teval-auc:0.73139\n",
      "[600]\ttrain-auc:0.74821\teval-auc:0.73283\n",
      "[800]\ttrain-auc:0.75276\teval-auc:0.73376\n",
      "[1000]\ttrain-auc:0.75685\teval-auc:0.73414\n",
      "[1200]\ttrain-auc:0.76081\teval-auc:0.73457\n",
      "[1400]\ttrain-auc:0.76453\teval-auc:0.73492\n",
      "[1600]\ttrain-auc:0.76802\teval-auc:0.73499\n",
      "[1800]\ttrain-auc:0.77140\teval-auc:0.73513\n",
      "[2000]\ttrain-auc:0.77472\teval-auc:0.73503\n",
      "[2018]\ttrain-auc:0.77498\teval-auc:0.73504\n",
      "调参后xgboost单模型在验证集上的AUC：0.7351769585810701\n",
      "2021-01-16 15:36:53,774 INFO: Calculating xgb's fold #3\n",
      "[15:36:54] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.69997\teval-auc:0.70114\n",
      "[200]\ttrain-auc:0.73280\teval-auc:0.72995\n",
      "[400]\ttrain-auc:0.74111\teval-auc:0.73390\n",
      "[600]\ttrain-auc:0.74665\teval-auc:0.73537\n",
      "[800]\ttrain-auc:0.75136\teval-auc:0.73620\n",
      "[1000]\ttrain-auc:0.75557\teval-auc:0.73677\n",
      "[1200]\ttrain-auc:0.75941\teval-auc:0.73710\n",
      "[1400]\ttrain-auc:0.76306\teval-auc:0.73737\n",
      "[1600]\ttrain-auc:0.76658\teval-auc:0.73747\n",
      "[1800]\ttrain-auc:0.77000\teval-auc:0.73748\n",
      "[1927]\ttrain-auc:0.77210\teval-auc:0.73750\n",
      "调参后xgboost单模型在验证集上的AUC：0.7375587904997395\n",
      "2021-01-16 15:52:16,103 INFO: Calculating xgb's fold #4\n",
      "[15:52:16] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.70059\teval-auc:0.69926\n",
      "[200]\ttrain-auc:0.73317\teval-auc:0.72930\n",
      "[400]\ttrain-auc:0.74101\teval-auc:0.73286\n",
      "[600]\ttrain-auc:0.74665\teval-auc:0.73447\n",
      "[800]\ttrain-auc:0.75139\teval-auc:0.73528\n",
      "[1000]\ttrain-auc:0.75552\teval-auc:0.73578\n",
      "[1200]\ttrain-auc:0.75957\teval-auc:0.73615\n",
      "[1400]\ttrain-auc:0.76331\teval-auc:0.73647\n",
      "[1600]\ttrain-auc:0.76693\teval-auc:0.73661\n",
      "[1800]\ttrain-auc:0.77044\teval-auc:0.73669\n",
      "[2000]\ttrain-auc:0.77366\teval-auc:0.73668\n",
      "[2200]\ttrain-auc:0.77695\teval-auc:0.73676\n",
      "[2400]\ttrain-auc:0.77983\teval-auc:0.73660\n",
      "[2406]\ttrain-auc:0.77992\teval-auc:0.73662\n",
      "调参后xgboost单模型在验证集上的AUC：0.7367723796088966\n",
      "2021-01-16 16:11:26,794 INFO: Calculating xgb's fold #5\n",
      "[16:11:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.70047\teval-auc:0.69871\n",
      "[200]\ttrain-auc:0.73438\teval-auc:0.72703\n",
      "[400]\ttrain-auc:0.74238\teval-auc:0.73050\n",
      "[600]\ttrain-auc:0.74803\teval-auc:0.73212\n",
      "[800]\ttrain-auc:0.75258\teval-auc:0.73295\n",
      "[1000]\ttrain-auc:0.75665\teval-auc:0.73334\n",
      "[1200]\ttrain-auc:0.76054\teval-auc:0.73352\n",
      "[1400]\ttrain-auc:0.76416\teval-auc:0.73377\n",
      "[1600]\ttrain-auc:0.76779\teval-auc:0.73394\n",
      "[1800]\ttrain-auc:0.77103\teval-auc:0.73402\n",
      "[2000]\ttrain-auc:0.77417\teval-auc:0.73410\n",
      "[2200]\ttrain-auc:0.77726\teval-auc:0.73409\n",
      "[2283]\ttrain-auc:0.77848\teval-auc:0.73407\n",
      "调参后xgboost单模型在验证集上的AUC：0.7341715772300048\n",
      "2021-01-16 16:29:41,506 INFO: Calculating xgb's test data\n",
      "[16:29:42] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.70079\teval-auc:0.69873\n",
      "[200]\ttrain-auc:0.73329\teval-auc:0.72679\n",
      "[400]\ttrain-auc:0.74075\teval-auc:0.73056\n",
      "[600]\ttrain-auc:0.74568\teval-auc:0.73219\n",
      "[800]\ttrain-auc:0.74980\teval-auc:0.73310\n",
      "[1000]\ttrain-auc:0.75334\teval-auc:0.73366\n",
      "[1200]\ttrain-auc:0.75672\teval-auc:0.73395\n",
      "[1400]\ttrain-auc:0.75990\teval-auc:0.73421\n",
      "[1600]\ttrain-auc:0.76292\teval-auc:0.73439\n",
      "[1800]\ttrain-auc:0.76566\teval-auc:0.73450\n",
      "[2000]\ttrain-auc:0.76843\teval-auc:0.73456\n",
      "[2200]\ttrain-auc:0.77117\teval-auc:0.73456\n",
      "[2400]\ttrain-auc:0.77381\teval-auc:0.73460\n",
      "[2600]\ttrain-auc:0.77627\teval-auc:0.73461\n",
      "[2742]\ttrain-auc:0.77800\teval-auc:0.73462\n",
      "调参后xgboost单模型在验证集上的AUC：0.7346551980188376\n",
      "2021-01-16 16:57:53,731 INFO: Calculating lgb's fold #1\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 0.724264\tvalid_1's auc: 0.724344\n",
      "[1000]\ttraining's auc: 0.730095\tvalid_1's auc: 0.729042\n",
      "[1500]\ttraining's auc: 0.733532\tvalid_1's auc: 0.731455\n",
      "[2000]\ttraining's auc: 0.736081\tvalid_1's auc: 0.732907\n",
      "[2500]\ttraining's auc: 0.738131\tvalid_1's auc: 0.733868\n",
      "[3000]\ttraining's auc: 0.739979\tvalid_1's auc: 0.734686\n",
      "[3500]\ttraining's auc: 0.741563\tvalid_1's auc: 0.7352\n",
      "[4000]\ttraining's auc: 0.743076\tvalid_1's auc: 0.735611\n",
      "[4500]\ttraining's auc: 0.744411\tvalid_1's auc: 0.735981\n",
      "[5000]\ttraining's auc: 0.745714\tvalid_1's auc: 0.736166\n",
      "[5500]\ttraining's auc: 0.746941\tvalid_1's auc: 0.736438\n",
      "[6000]\ttraining's auc: 0.748052\tvalid_1's auc: 0.736595\n",
      "[6500]\ttraining's auc: 0.749218\tvalid_1's auc: 0.736773\n",
      "[7000]\ttraining's auc: 0.750255\tvalid_1's auc: 0.736933\n",
      "[7500]\ttraining's auc: 0.751272\tvalid_1's auc: 0.737117\n",
      "[8000]\ttraining's auc: 0.752265\tvalid_1's auc: 0.737215\n",
      "Early stopping, best iteration is:\n",
      "[7942]\ttraining's auc: 0.752171\tvalid_1's auc: 0.737219\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7372191716272272\n",
      "2021-01-16 17:11:25,081 INFO: Calculating lgb's fold #2\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 0.725667\tvalid_1's auc: 0.723116\n",
      "[1000]\ttraining's auc: 0.731548\tvalid_1's auc: 0.727861\n",
      "[1500]\ttraining's auc: 0.734975\tvalid_1's auc: 0.730136\n",
      "[2000]\ttraining's auc: 0.737428\tvalid_1's auc: 0.731368\n",
      "[2500]\ttraining's auc: 0.739481\tvalid_1's auc: 0.732326\n",
      "[3000]\ttraining's auc: 0.741249\tvalid_1's auc: 0.73297\n",
      "[3500]\ttraining's auc: 0.742822\tvalid_1's auc: 0.733626\n",
      "[4000]\ttraining's auc: 0.74428\tvalid_1's auc: 0.734043\n",
      "[4500]\ttraining's auc: 0.745624\tvalid_1's auc: 0.734441\n",
      "[5000]\ttraining's auc: 0.746927\tvalid_1's auc: 0.734699\n",
      "[5500]\ttraining's auc: 0.748087\tvalid_1's auc: 0.734905\n",
      "[6000]\ttraining's auc: 0.749257\tvalid_1's auc: 0.735144\n",
      "[6500]\ttraining's auc: 0.750295\tvalid_1's auc: 0.735267\n",
      "[7000]\ttraining's auc: 0.751376\tvalid_1's auc: 0.735433\n",
      "[7500]\ttraining's auc: 0.752402\tvalid_1's auc: 0.73554\n",
      "[8000]\ttraining's auc: 0.75343\tvalid_1's auc: 0.73561\n",
      "[8500]\ttraining's auc: 0.754409\tvalid_1's auc: 0.735682\n",
      "Early stopping, best iteration is:\n",
      "[8316]\ttraining's auc: 0.754025\tvalid_1's auc: 0.73569\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7356903766440643\n",
      "2021-01-16 17:25:49,824 INFO: Calculating lgb's fold #3\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 0.725218\tvalid_1's auc: 0.720737\n",
      "[1000]\ttraining's auc: 0.731027\tvalid_1's auc: 0.725304\n",
      "[1500]\ttraining's auc: 0.734423\tvalid_1's auc: 0.727494\n",
      "[2000]\ttraining's auc: 0.737079\tvalid_1's auc: 0.729034\n",
      "[2500]\ttraining's auc: 0.739063\tvalid_1's auc: 0.73\n",
      "[3000]\ttraining's auc: 0.740824\tvalid_1's auc: 0.73073\n",
      "[3500]\ttraining's auc: 0.742511\tvalid_1's auc: 0.731334\n",
      "[4000]\ttraining's auc: 0.743936\tvalid_1's auc: 0.731822\n",
      "[4500]\ttraining's auc: 0.745269\tvalid_1's auc: 0.732185\n",
      "[5000]\ttraining's auc: 0.746609\tvalid_1's auc: 0.73255\n",
      "[5500]\ttraining's auc: 0.747881\tvalid_1's auc: 0.732703\n",
      "[6000]\ttraining's auc: 0.749023\tvalid_1's auc: 0.732869\n",
      "[6500]\ttraining's auc: 0.750099\tvalid_1's auc: 0.73301\n",
      "[7000]\ttraining's auc: 0.751147\tvalid_1's auc: 0.733174\n",
      "[7500]\ttraining's auc: 0.752135\tvalid_1's auc: 0.733224\n",
      "[8000]\ttraining's auc: 0.753131\tvalid_1's auc: 0.733285\n",
      "Early stopping, best iteration is:\n",
      "[8119]\ttraining's auc: 0.753366\tvalid_1's auc: 0.733307\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7333066499415493\n",
      "2021-01-16 17:39:40,623 INFO: Calculating lgb's fold #4\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 0.724884\tvalid_1's auc: 0.723297\n",
      "[1000]\ttraining's auc: 0.730859\tvalid_1's auc: 0.727681\n",
      "[1500]\ttraining's auc: 0.734419\tvalid_1's auc: 0.729951\n",
      "[2000]\ttraining's auc: 0.736816\tvalid_1's auc: 0.731183\n",
      "[2500]\ttraining's auc: 0.73895\tvalid_1's auc: 0.73212\n",
      "[3000]\ttraining's auc: 0.740611\tvalid_1's auc: 0.732758\n",
      "[3500]\ttraining's auc: 0.742255\tvalid_1's auc: 0.733306\n",
      "[4000]\ttraining's auc: 0.743704\tvalid_1's auc: 0.733777\n",
      "[4500]\ttraining's auc: 0.745014\tvalid_1's auc: 0.734011\n",
      "[5000]\ttraining's auc: 0.746312\tvalid_1's auc: 0.734318\n",
      "[5500]\ttraining's auc: 0.747583\tvalid_1's auc: 0.73455\n",
      "[6000]\ttraining's auc: 0.748682\tvalid_1's auc: 0.734744\n",
      "[6500]\ttraining's auc: 0.749794\tvalid_1's auc: 0.734886\n",
      "[7000]\ttraining's auc: 0.750873\tvalid_1's auc: 0.73503\n",
      "[7500]\ttraining's auc: 0.751901\tvalid_1's auc: 0.735099\n",
      "[8000]\ttraining's auc: 0.752887\tvalid_1's auc: 0.735181\n",
      "[8500]\ttraining's auc: 0.753899\tvalid_1's auc: 0.73525\n",
      "Early stopping, best iteration is:\n",
      "[8707]\ttraining's auc: 0.754297\tvalid_1's auc: 0.735297\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7352970176674067\n",
      "2021-01-16 17:54:45,255 INFO: Calculating lgb's fold #5\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 0.725267\tvalid_1's auc: 0.722874\n",
      "[1000]\ttraining's auc: 0.731211\tvalid_1's auc: 0.727744\n",
      "[1500]\ttraining's auc: 0.734674\tvalid_1's auc: 0.730114\n",
      "[2000]\ttraining's auc: 0.737091\tvalid_1's auc: 0.731366\n",
      "[2500]\ttraining's auc: 0.739131\tvalid_1's auc: 0.732365\n",
      "[3000]\ttraining's auc: 0.740873\tvalid_1's auc: 0.733093\n",
      "[3500]\ttraining's auc: 0.742465\tvalid_1's auc: 0.733644\n",
      "[4000]\ttraining's auc: 0.74394\tvalid_1's auc: 0.734123\n",
      "[4500]\ttraining's auc: 0.745317\tvalid_1's auc: 0.734525\n",
      "[5000]\ttraining's auc: 0.746593\tvalid_1's auc: 0.734801\n",
      "[5500]\ttraining's auc: 0.747764\tvalid_1's auc: 0.735084\n",
      "[6000]\ttraining's auc: 0.748977\tvalid_1's auc: 0.735324\n",
      "[6500]\ttraining's auc: 0.750124\tvalid_1's auc: 0.73549\n",
      "[7000]\ttraining's auc: 0.751172\tvalid_1's auc: 0.73566\n",
      "[7500]\ttraining's auc: 0.752195\tvalid_1's auc: 0.735716\n",
      "Early stopping, best iteration is:\n",
      "[7349]\ttraining's auc: 0.751869\tvalid_1's auc: 0.735728\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7357275200633664\n",
      "2021-01-16 18:07:25,614 INFO: Calculating lgb's test data\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's auc: 0.724372\tvalid_1's auc: 0.724629\n",
      "[1000]\ttraining's auc: 0.730271\tvalid_1's auc: 0.729243\n",
      "[1500]\ttraining's auc: 0.733637\tvalid_1's auc: 0.731513\n",
      "[2000]\ttraining's auc: 0.736021\tvalid_1's auc: 0.732919\n",
      "[2500]\ttraining's auc: 0.737896\tvalid_1's auc: 0.733774\n",
      "[3000]\ttraining's auc: 0.739562\tvalid_1's auc: 0.734422\n",
      "[3500]\ttraining's auc: 0.740958\tvalid_1's auc: 0.734905\n",
      "[4000]\ttraining's auc: 0.742238\tvalid_1's auc: 0.735329\n",
      "[4500]\ttraining's auc: 0.74352\tvalid_1's auc: 0.735756\n",
      "[5000]\ttraining's auc: 0.744622\tvalid_1's auc: 0.736049\n",
      "[5500]\ttraining's auc: 0.745696\tvalid_1's auc: 0.736298\n",
      "[6000]\ttraining's auc: 0.746719\tvalid_1's auc: 0.736499\n",
      "[6500]\ttraining's auc: 0.747692\tvalid_1's auc: 0.736634\n",
      "[7000]\ttraining's auc: 0.748625\tvalid_1's auc: 0.736749\n",
      "[7500]\ttraining's auc: 0.749547\tvalid_1's auc: 0.73685\n",
      "[8000]\ttraining's auc: 0.750386\tvalid_1's auc: 0.736932\n",
      "Early stopping, best iteration is:\n",
      "[8137]\ttraining's auc: 0.750615\tvalid_1's auc: 0.73695\n",
      "调参后lightgbm单模型在验证集上的AUC：0.7369498916672799\n",
      "CPU times: user 6h 32min 43s, sys: 2min 7s, total: 6h 34min 51s\n",
      "Wall time: 3h 18min 48s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.09313586, 0.35738364, 0.71145548, ..., 0.15995634, 0.18775493,\n",
       "       0.07224607])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# 第二层使用逻辑回归进行 stack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stacker = Classifier(dataset=stack_ds, estimator=LogisticRegression, parameters={'solver': 'lbfgs'})\n",
    "test_pred = stacker.predict()\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       id  isDefault\n",
       "0  800000   0.093136\n",
       "1  800001   0.357384\n",
       "2  800002   0.711455\n",
       "3  800003   0.294181\n",
       "4  800004   0.380386\n",
       "5  800005   0.068497\n",
       "6  800006   0.264772\n",
       "7  800007   0.076216\n",
       "8  800008   0.780822\n",
       "9  800009   0.075935"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>isDefault</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800000</td>\n      <td>0.093136</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>800001</td>\n      <td>0.357384</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>800002</td>\n      <td>0.711455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>800003</td>\n      <td>0.294181</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800004</td>\n      <td>0.380386</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>800005</td>\n      <td>0.068497</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>800006</td>\n      <td>0.264772</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>800007</td>\n      <td>0.076216</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>800008</td>\n      <td>0.780822</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>800009</td>\n      <td>0.075935</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# 生成提交格式的DataFrame\n",
    "df_result = pd.DataFrame({'id': data.loc[data['sample'] == 'test', 'id'].values, 'isDefault': test_pred})\n",
    "df_result.sort_values(by='id').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('data/tc/pred_stacking.csv', index=False)"
   ]
  },
  {
   "source": [
    "#### 使用blending方法进行模型融合"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a6c8ca6635f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 构建第一层新特征，将训练集切分为8：2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mblend_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproportion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mblender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblend_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'solver'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/heamy/pipeline.py\u001b[0m in \u001b[0;36mblend\u001b[0;34m(self, proportion, stratify, seed, indices, add_diff)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproportion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproportion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/heamy/estimator.py\u001b[0m in \u001b[0;36mblend\u001b[0;34m(self, proportion, stratify, seed, indices)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mxt_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mprediction_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/heamy/estimator.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# function-based definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             result = self._estimator(X_train=X_train, y_train=y_train,\n\u001b[0m\u001b[1;32m    121\u001b[0m                                      X_test=X_test, y_test=y_test, **self.parameters)\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-6a548f0d62a8>\u001b[0m in \u001b[0;36mcat_model\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     )\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    }
   ],
   "source": [
    "# 构建第一层新特征，将训练集切分为8：2\n",
    "blend_ds = pipeline.blend(proportion=0.2, seed=111)\n",
    "blender = Classifier(dataset=blend_ds, estimator=LogisticRegression, parameters={'solver': 'lbfgs'})\n",
    "test_pred = blender.predict()\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       id  isDefault\n",
       "0  800000   0.092102\n",
       "1  800001   0.356927\n",
       "2  800002   0.657772\n",
       "3  800003   0.284317\n",
       "4  800004   0.398475\n",
       "5  800005   0.067065\n",
       "6  800006   0.289313\n",
       "7  800007   0.076159\n",
       "8  800008   0.748041\n",
       "9  800009   0.075634"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>isDefault</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800000</td>\n      <td>0.092102</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>800001</td>\n      <td>0.356927</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>800002</td>\n      <td>0.657772</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>800003</td>\n      <td>0.284317</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800004</td>\n      <td>0.398475</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>800005</td>\n      <td>0.067065</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>800006</td>\n      <td>0.289313</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>800007</td>\n      <td>0.076159</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>800008</td>\n      <td>0.748041</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>800009</td>\n      <td>0.075634</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# 生成提交格式的DataFrame\n",
    "df_result = pd.DataFrame({'id': data.loc[data['sample'] == 'test', 'id'].values, 'isDefault': test_pred})\n",
    "df_result.sort_values(by='id').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('data/tc/pred_blending_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}